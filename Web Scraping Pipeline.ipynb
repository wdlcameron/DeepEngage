{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.IG_Scraper import InstagramBot\n",
    "from scripts.dataframe_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of scraping with the InstagramBot()\n",
    "\n",
    "InstagramBot scrapes Instagram posts and their associated metrics from lists of users, then organizes then in a .csv file. Checks have been introduced to circumvent access blocking by taking actions at speeds more similar to the average, while also minimizing abnormal behaviour (e.g. repeatedly accessing the same pages, refreshing pages unecessarily etc.).  To that end, the bot will prioritize skipping a post when issues arise, but these can be filled in later during the cleanup stage.\n",
    "\n",
    "Choosing a new niche to scrape involves the following steps:\n",
    "\n",
    "1) Import or create a list of accounts that are representative of your niche\n",
    "\n",
    "2) Create an InstagramBot() instance  (e.g.  IB)\n",
    "\n",
    "3) Sign into your scraping account ->  IB.signIn()\n",
    "\n",
    "4) Gather the posts of those users  -> IB.posts_from_list_of_users()\n",
    "\n",
    "5) Fill in the dataframe ->  IB.fill_in_dataframe()   Note: the previous step gathers user, so pass include_user = False.  \n",
    "                Additional Note: you may wish to run this twice to catch any posts that were missed during the first round.\n",
    "                Additional Note: In the event of issues arising during the scraping process (e.g. you must shut down the computer), a temporary csv file will be exported every 20 posts and can be reloaded to resume scraping at a later time.\n",
    "                \n",
    "6) Post-processing of the dataframe  -> post_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Choose the data folder for your scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main Variables:\n",
    "\n",
    "root_directory: where all of the files related to this particular niche will be stored.\n",
    "image_directory: where all of the images will be saved\n",
    "dataframe_directory: where imports/outputs will be located\n",
    "dataframe_name: desired dataframe name\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "root_dir = Path(r'C:\\Users\\William\\Google Drive (william.dl.cameron@gmail.com)\\Insight Project')\n",
    "df_dir = root_dir/'Output_Guys'; image_directory.mkdir(exist_ok = True, parents = True)\n",
    "image_directory = root_dir/'Images'; image_directory.mkdir(exist_ok = True, parents = True)\n",
    "df_name = 'food_dataframe.csv'\n",
    "\n",
    "\n",
    "df_path = df_dir/df_name\n",
    "df = load_dataframe(df_path) if df_path.exists() else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fill in your account details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = 'webscraper100'\n",
    "password = 'ScrapingTheWeb100'\n",
    "\n",
    "\n",
    "IB = InstagramBot(username,password)\n",
    "IB.signIn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Run this if you need to refresh your InstagramBot instance in the same browser (ex. code change)\"\"\"\n",
    "IB = InstagramBot(username,password, IB.browser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Gather posts and related information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a userlist from a text file\n",
    "with open(Path('userlists')/'FoodUsers.txt') as f:\n",
    "    user_list = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    \n",
    "\"\"\"Alternatively, you can manually create your own.  Use a set to avoid duplicates\"\"\"\n",
    "# user_list = {'localhaven',\n",
    "#                 'feedtheswimmers',\n",
    "#                 'smittenkitchen',\n",
    "#                 'wellandfull',\n",
    "#                }\n",
    "# user_list = list(set(user_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = IB.posts_from_list_of_users(user_list, df = df)\n",
    "export_df(df, df_dir/f'prefilled_{df_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataframe(df_dir/f'prefilled_{df_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Step 3: Scrape information from the posts\"\"\"\n",
    "\n",
    "df = IB.fill_in_dataframe(df, include_user = False, output_folder = df_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(df_dir/'filled_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process the Dataframe (Data Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataframe(df_dir/'filled_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = post_processing(df, df_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(df_dir/'processed_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Links', 'filename', 'followers', 'following', 'num_posts', 'username',\n",
       "       'likes', 'posttime', 'alt-text', 'caption', 'tags',\n",
       "       'Engagement (Avg Likes)', 'Downloaded', 'engagement_factor_avg_likes',\n",
       "       'rolling_avg', 'engagement_factor_moving_avg', 'date', 'hour', 'minute',\n",
       "       'second', 'month', 'year', 'day_name', 'performance', 'red', 'green',\n",
       "       'blue', 'brightness', 'red_range', 'green_range', 'blue_range',\n",
       "       'contrast', 'rolling', 'engagement_factor_std',\n",
       "       'rel_contrast_moving_avg', 'rel_brightness_moving_avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground - For Testing out new Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
